# Overview

Many of our partners have extensively used Lotus sealing components and are no strangers to customizing them.

During use, they have encountered many pain points and summarized a lot of empirical knowledge. We compiled these thoughts and tried to provide a set of cluster solutions that took an approach not entirely identical to that of Lotus sealing components, but still competitive, with simplicity, efficiency, and flexibility as the top priorities, for storage providers (SPs) to choose from.



## Design Considerations

Damocles mainly includes the components `damocles-manager` and `damocles-worker`, whose functions are roughly equivalent to the combination of `lotus-miner` and `lotus-worker`.



Damocles focuses on implementing a set of efficient sealing cluster solutions that accomplish goals including

- When faced with many homogeneous computing devices, reduce the number of types of hardware required, the number of instances, and the complexity of deployment.
- Safely complete "self-healing" for abnormalities in various stages and of different types as much as possible, reducing manual intervention and improving production efficiency.
- Utilize cloud services, outsourcing services, and other sharable infrastructure to lower thresholds of entry into the industry and reduce unnecessary costs.



Of course, this clear and targeted design may make this set of solutions not universally suitable for all users. For example, if the user already owns a large number of devices configured separately for different stages of sealing forming appropriate combinations, then the Damocles solution may not effectively improve the sealing efficiency. The user can judge the specific circumstances wherein using Damocles is appropriate after reading subsequent documentations.



### Lotus sealing component mechanism

Before introducing Damocles-specific design approaches, we need to review the mechanism of Lotus-related components.

The Lotus sealing components form a standard centralized scheduling cluster:

- `lotus-miner` is the central scheduling service that allocates and manages tasks.
- `lotus-seal-worker` is the sealing execution body, responsible for completing the specific tasks assigned to it and providing feedback to `lotus-miner`.

`lotus-miner`, as the initiator, interacts with `lotus-seal-worker` via RPC.



The advantages of this design are obvious:

- `lotus-seal-worker` is an almost stateless working process that is theoretically easy to scale out horizontally.
- `lotus-miner` can flexibly schedule tasks among `lotus-worker` instances.



But this mechanism also has another side:

1. `lotus-miner`, as the scheduling core:

   - Bears heavy and different types of logic, such as task scheduling and management, interacting with the chain, etc.
   - Retains the historical burden of having to be compatible with both local mode and remote mode at the same time.
  
   These lead to complex internal logic (state machine) and difficulty in refining exception handling.

2. `lotus-seal-worker` is designed to be completely stateless.



This has led to some problems, such as:

1. Due to the vastly different hardware requirements between stages, in order to ensure reasonable resource allocation, `lotus-seal-worker` is usually configured so that each instance only supports tasks from one stage, and multiple different instances are deployed on the same machine, isolated through OS-level resource control (cgroups, docker, numa, etc.).  
This results in a large number of `lotus-seal-worker` instances in large-scale clusters, making orchestration and management relatively complex.

2. Any centralized task scheduling mechanism is likely to require consideration of computation and storage resource matching and affinity.  
We said that `lotus-seal-worker` is almost stateless, but there is a special "context" in the form of **temporary files** during sector sealing. For a long time, `lotus-miner` simply moved them whole. This resulted in huge network bandwidth costs and a series of network and storage abnormalities that can follow.  
It was not until [PR 7453](https://github.com/filecoin-project/lotus/pull/7453) proposed the concept of "storage groups" that affinity issues were preliminarily resolved, but this approach added extra complexity to worker orchestration.

3. In large-scale clusters, numerous factors can cause task abnormalities, including but not limited to computation errors, storage failures, and network jitters. `lotus-miner` lacks effective means internally to discern the root causes of abnormalities, making it difficult to choose different recovery mechanisms based on the specific reason, and can only handle uniformly in coarse granularity or wait for manual intervention.



### Damocles's design philosophy

Based on our goals and experience, we established several objectives for Damocles at the beginning of its design:

- Simplify logic
- Optimize processes
- Isolate abnormalities
- Reduce deployment complexity
- Flexibly replace components



We will elaborate on them below.



#### Simplify logic

We re-planned the division of responsibilities between upstream and downstream components:

- `damocles-manager` is responsible for
  - Chain interactions during sector sealing, such as getting `Ticket` and `Seed`, independent or aggregate message submissions, etc.
  - Keeping track of the state of sector sealing tasks, such as current stage, abnormalities and their respective causes, etc.
  - Management and maintenance of sealed sectors, such as handling `WindowPoSt`, etc.
- `Damocles-worker` is responsible for:
  - Managing the allocation of compution resources for each stage
  - Completing the entire sector sealing process using pre-planned local storage space



Through this division, `damocles-manager` only needs to passively receive the necessary information, without having to implement a complex sensing and scheduling system; `damocles-worker` directly manages various local abnormalities, making it easier to execute different handling strategies.

Thus, the business logic of both will not frequently branch out, making them relatively easy to understand and modify.



#### Optimize processes

The biggest problem in the Lotus sealing process is the handling of temporary files during the sealing process, as mentioned above. In addition, there are some other unsatisfactory points, such as:

- The waiting logic of orders may lead to idle computing resources.
- Forced one-to-one matching of storage resources and computing resources.
- In some stages, the demands for resources are inconsistent between multiple internal links.
- Bundling the interaction with the chain and the sector sealing computation, resulting in untimely release of storage space, etc.

All of these will affect the overall efficiency of sealing. Damocles aims to alleviate these problems.



#### Isolate abnormalities

On one hand, the main abnormality handling has been moved to the `damocles-worker` layer, and in the design of the interface of interaction with `damocles-manager`, the distinction between network anomalies and logic anomalies was considered as early as possible, so that `damocles-worker` can perceive the specific causes of anomalies relatively easily.

On the other hand, we classified the types of errors that may occur during the sealing process into four levels, and set different handling methods:

- temp(orary): 
  Errors of this level are usually clearly temporary, or we know that retries will not have negative effects.
  For such errors, the `worker` will automatically retry (at intervals of `recover_interval`, up to `max_retries` times).   
  When the number of retries exceeds the set upper limit, it will automatically be upgraded to the `perm` level.
  RPC errors are a typical example of temporary error types.

- perm(anent): 
  Errors that we cannot simply judge whether retries can be done safely or that will yield relatively greater benefits once fixed (e.g. no need to redo pre commit phase1) belong to this level. Such errors usually occur during `sealing`.  
  Errors of this level will block the `worker` thread until manual intervention is completed.

- crit(ical): 
  Critical-level errors are similar in many ways to permanent level errors.  
  A significant difference is that critical-level errors usually clearly come from the running environment rather than the `sealing` process. For example, this category includes distinguishable local file system abnormalities, local persistent database abnormalities, etc.  
  Critical-level errors will also block `worker` threads until manual intervention.

- abort: 
  When encountering errors at this level, `worker` will directly abandon the current `sealing` progress and try to start a new process.



This allows `damocles-worker` to self-recover in more scenarios without manual intervention and provides room for users to customize abnormality handling strategies.



#### Reduce deployment complexity

`damocles-worker` reduces deployment complexity mainly by:

- Reducing the number of instances.
- Reducing differentiated configurations.
- Reducing hardware failures, especially the impact scope of storage failures.



`damocles-worker` is designed to be deployed as one instance per device while incorporating streamlined but sufficient resource control and isolation internally. Users can decide resource allocation strategies based on actual situations to achieve maximum efficiency. At the same time, sector-granularity task isolation can also ensure that partial hardware failures do not spread to affect other sector tasks.



`damocles-manager` is designed so that one instance can serve multiple different SPs. Combined with the design of the Venus series of chain service components, they can achieve some uncommon operation methods:

- SP unions
- Multi-cluster collaboration using cloud vendor devices
- Dynamic scheduling under computing devices shared by multiple SPs



#### Flexibly replace components

For many components within Damocles, we abstracted their interfaces before actually implementing them. This approach ensures that we constrain parts only when necessary and retain the possibility of the coexistence of different implementations, more easily supporting functions including

- Customized or proprietary sealing algorithm executors
- Shared order data storage
- Outsourcing services for some stages





## Summary
We do not define Damocles as an all-powerful sealing cluster solution. We hope it is a choice for users who need simplicity, efficiency, and flexibility in specific scenarios.

At the same time, we look forward to the introduction of richer component implementations from more participants.

We believe that expanding the coverage of "specific scenarios" will help expand the audience for Damocles, but we will not rashly promise to meet all feature demands for Damocles, especially those that affect its distinctive characteristics.

