# Standalone PoSter node

In earlier versions, although `venus-sector-manager` supports using `--poster` and `--miner` parameters of the `daemon run` command to enable the corresponding module, the `post` proof process is still of strong correlation with sector location information which makes it more limited and difficult to expand.

From v0.2.0 onwards, we have provided a series of functional combinations that make easy-to-use, scalable standalone PoSter nodes an option for `SP` with large-scale operations.

Below, we will introduce these new features and provide a practice to complete the deployment of standalone PoSter nodes using these features. Subsequent documents use the node with `--poster` enabled as an example, and the standalone `--miner` node operates in a similar manner, which will not be described separately.

## Proxy node mode
We know that for PoSter nodes, the most important capability is to obtain real-time and accurate sector location information. In the current `venus-sector-manager` version, we only provide metadata management based on the local embedded kv database (more to be supported).

This only allows data to be managed by one process, and direct data sharing across processes is not possible.

Therefore, we designed the proxy node mode to provide some metadata to other consumer nodes through network interfaces, thus realizing data sharing.

### How to use the proxy node
We have added the `--proxy` parameter to the `daemon run` command. Its format is like `{ip}:{port}`. When the startup command contains a valid `--proxy` parameter, `{ip}:{port}` will be used as data source for the current `venus-sector-manager` node and the necessary metadata (read-only) management module will be constructed.

In addition to `--proxy`, we also provide switches that control whether proxy mode is enabled for specific data management modules.

We just provide `--proxy-sector-indexer-off` switch for the time being. When `--proxy-sector-indexer-off` is enabled, nodes use the `SectorIndexer` database in their own data directory.

For example, if started with the `venus-sector-manager daemon run --miner` command, it will launch a `venus-sector-manager` instance listening on port `1789` using `~/.venus-sector-manager` as the data directory with mining module enabled.

At this time, we can use the following command to initialize and start a proxy node with the above instance as the data source on the same machine. This proxy node will use `~/.venus-sector-manager2` as the data directory and listen to `2789` port.
````
venus-sector-manager --home ~/.venus-sector-manager2 daemon init
// maintain configuration files
venus-sector-manager --home ~/.venus-sector-manager2 daemon run --proxy="127.0.0.1:1789" --listen=":2789" --poster
````

The proxy node can provide the exact same and real-time sector location information as the source node.

### The agent node uses the existing configuration file
According to the method described in the previous section, we can already start an proxy node, but there is still a problem with this startup method: the configuration file of the proxy node needs to be written again, or copied from the data directory of the source node. This introduces additional maintenance work, especially when configuration files may change frequently.

For this, we also provide a `--conf-dir` parameter, which is in the form of a directory path. When the startup command includes a valid `--conf-dir` parameter, the node will use the configuration file that already exists in the specified directory as its own configuration file.

This saves the work of writing and maintaining configuration files for different source and agent nodes on the same machine and serving the same set of clusters.

Based on this function, the agent node startup method mentioned in the previous section can become:
````
venus-sector-manager --home ~/.venus-sector-manager2 daemon run --proxy="127.0.0.1:1789" --listen=":2789" --conf-dir="~/.venus-sector-manager" --poster
````

At this point, the source node and the proxy node will use the same batch of configuration files.


## ext-prover executor
In addition to sharing sector information, another challenge faced by standalone PoSter nodes is the utilization of hardware resources.

Limited by the underlying algorithm library, granularity of computing nodes utilizing GPUs is by process. This makes it difficult for PoSter nodes to effectively utilize the computing power of multiple GPUs, and it is also difficult to safely avoid proof timeouts when multiple `SP`s have conflicting `WindostPoSt` proof windows.

For this, we provide an `ext-prover` mechanism similar to the `ext processor` in `venus-worker`.

The `ext-prover` mechanism consists of two components:
1. The `--ext-prover` parameter of the `daemon run` command
2. The `ext-prover.cfg` configuration file in the node data directory

A default `ext-prover.cfg` file looks like:
````
# Default config:
#[[WdPost]]
#Bin = "/path/to/custom/bin"
#Args = ["args1", "args2", "args3"]
#Concurrent = 1
#Weight = 1
#ReadyTimeoutSecs = 5
#[WdPost.Envs]
#ENV_KEY = "ENV_VAL"
#
#[[WinPost]]
#Bin = "/path/to/custom/bin"
#Args = ["args1", "args2", "args3"]
#Concurrent = 1
#Weight = 1
#ReadyTimeoutSecs = 5
#[WinPost.Envs]
#ENV_KEY = "ENV_VAL"
#
````

In recent versions, `daemon init` initializes the `ext-prover.cfg` file.

Users can write their own, or copy the corresponding files from a data directory initialized by the latest version to an existing data directory.

The functions of the configuration items in `ext-prover.cfg` are very similar to the configuration blocks in `venus-worker`, and users can refer to the corresponding documents for reference.

When the `--ext-prover` parameter is included in the start command of `venus-sector-manager`, the node will use the `ext-prover.cfg` configuration file in the configuration directory as the basis for starting child processes. For this configuration file, setting the `--conf-dir` parameter will also have an effect.

If user sees logs like the following, then it means that `ext-prover` is ready.
````
2022-04-27T19:15:00.441+0800 INFO porver-ext ext/prover.go:122 response loop start {"pid": 24764, "ppid": 24732, "loop": "resp"}
2022-04-27T19:15:00.441+0800 INFO porver-ext ext/prover.go:155 request loop start {"pid": 24764, "ppid": 24732, "loop": "req"}
2022-04-27T19:15:00.468+0800 INFO processor-cmd processor/processor.go:35 ready {"pid": 24764, "ppid": 24732, "proc": "wdpost"}
````


## Deployment Practice
Suppose we have a node machine with 8 GPUs, then we can provide stronger PoSt processing capabilities through the following configuration.

1. Configure and start the source node
   ````
   venus-sector-manager daemon run --miner
   ````
   At this time, the source node only provides functions and capabilities related to sealing;

2. Configure the `ext-prover.cfg` file:
   ````
   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "0"
   TMPDIR = "/tmp/ext-prover0/"

   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "1"
   TMPDIR = "/tmp/ext-prover1/"

   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "2"
   TMPDIR = "/tmp/ext-prover2/"

   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "3"
   TMPDIR = "/tmp/ext-prover3/"

   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "4"
   TMPDIR = "/tmp/ext-prover4/"

   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "5"
   TMPDIR = "/tmp/ext-prover5/"

   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "6"
   TMPDIR = "/tmp/ext-prover6/"

   [[WdPost]]
   [WdPost.Envs]
   CUDA_VISIBLE_DEVICES = "7"
   TMPDIR = "/tmp/ext-prover7/"

   ````

3. Initialize and start a standalone `PoSter` node
   ````
   venus-sector-manager --home=~/.venus-individual-poster daemon init
   venus-sector-manager --home=~/.venus-individual-poster daemon run --proxy="127.0.0.1:1789" --poster --listen=":2789" --conf-dir="~/.venus-sector-manager" --ext-prover
   ````

By this way of deployment,
- The source node provides both sealing and mining support
- Proxy nodes provide `WindowPoSt` support
  - The proxy node enables `ext-prover`, and each child process independently uses a GPU and a computing lock directory

There is no conflict between `winningPost` and `windowPost` due to device usage

## Limitations
So far, we have described the functions, principles and simple usage examples that stand-alone `PoSter` nodes rely on.

However, this mode still has some limitations for very large `SP` clusters, which may manifest in:
- Unless the configuration is split, `PoSter` node can only provide `PoSt` support for some miners, it is difficult to provide horizontal scalability across machines;
- The scheduling of the `PoSt` and the serious conflict in the `PoSt` window period still relies on the operation and maintenance to a certain extent;

In general, the above limitations rely on a fully state decoupled, distributed `venus-sector-manager`implementation, which is one of the directions we focus on in the future.